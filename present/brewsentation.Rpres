Beer-in-Hand Data Science
========================================================
author: Amanda Dobbyn
date: 
autosize: true

<style>

  .title-slide {
     background-image: url(https://cdn.stocksnap.io/img-thumbs/960w/ZXWXE8FAJN.jpg);
      background-position: center center;
      background-attachment: fixed;
      background-repeat: no-repeat;
      background-size: 100% 100%;
      overflow: fixed;
   }
   
  .section .reveal .state-background {
      background-image: url(https://cdn.stocksnap.io/img-thumbs/960w/ZXWXE8FAJN.jpg);
      background-position: center center;
      background-attachment: fixed;
      background-repeat: no-repeat;
      background-size: 100% 100%;
  }
  
  body {
    overflow: scroll;
    border-style: solid;
  }
  
  .small-code pre code {
    font-size: 1em;
  }
  
  .very-small-code pre code {
    font-size: .7em;
  }
  
  b { 
    font-weight: bold;
    color: black;
  }
    
  table, td, th {
    border: 1px solid black;
    border-spacing: 5px;
    font-size: 1pt;
    padding: 5px, 5px, 5px, 5px;
    text-align: right;
    font-size: 1pt;
    overflow: scroll;
  }
  
  th {
    background-color: #e1e3e8;
  }
  
  .footer {
    color: black; 
    position: fixed; top: 90%;
    margin: top: 20%;
    text-align:center; width:100%;
}

  .midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
  }
  
  .cheers {
    background-image: url(https://cdn.stocksnap.io/img-thumbs/960w/ZXWXE8FAJN.jpg);
    background-position: center center;
    background-attachment: fixed;
    background-repeat: no-repeat;
    background-size: 100% 100%;
    color: white;
    border-style: none;
    background-size: 100% auto;
  }
  
  .cheers .reveal .state-background {
    background-image: url(https://cdn.stocksnap.io/img-thumbs/960w/ZXWXE8FAJN.jpg);
    background-position: center center;
    background-attachment: fixed;
    background-repeat: no-repeat;
    background-size: 100% 100%;
    color: white;
    border-style: none;
    background-size: 100% auto;
  }
  
  .cheers pre code {
    font-size: .7em;
    background: transparent;
    border-style: none;
  }
  
</style>

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache=TRUE, eval=FALSE)

# Set the working directory path to one directory up so this .Rmd file's working directory is the same as the R Project directory. This way we don't have to change the file paths when sourcing in.
knitr::opts_chunk$set(root.dir=normalizePath('../'))
knitr::opts_knit$set(root.dir=normalizePath('../'))
```

```{r source_in, eval=TRUE, echo=FALSE, message=FALSE}
library(broom)
library(jsonlite)
library(ggrepel)
devtools::install_github("aedobbyn/dobtools")
library(dobtools)
library(tidyverse)
library(forcats)
library(feather)
library(nnet)
library(caret)
library(emo)
library(NeuralNetTools)

# Data
beer_necessities <- read_feather("./beer_necessities.feather") %>% as_tibble()
beer_dat <- read_feather("./beer_dat.feather") %>% as_tibble()

# Helper functions
source("./run_it/key.R")
source("./helpers/run_neural_net.R")
```


```{r beer_caps, echo=FALSE, eval=TRUE}
# For cap_a_word_partial()
words_to_cap <- c("abv", "ibu", "srm", "id", 
                "Abv", "Ibu", "Srm", "Id")
```


First things first
========================================================
incremental:true
*Who am I?*

UChicago '15
![uchi_ultimate](./img/supersnatch.jpg)
<small> ^ Angela not yet pictured </small>


***
<br> 

Now at [Earlybird Software](http://earlybird.co/)
![eb](./img/eb_planning.jpg)

First things first
========================================================
incremental:false

<br>

*Where's the code?*

<https://github.com/aedobbyn/beer-data-science>
- Markdown writeup in `/compile`
- Shiny app in `/clusterfun`
- Step-by-step scripts for getting and munging data in `/run_it`
- This presentation in `/present`

***

<br>

![writeup](./img/writeup.jpg)


How did this come about?
========================================================
- Typical Friday afternoon office conversation
    - How do you architect the ideal beer flavor profile visualizer?
        - In particular, how do you represent *"hoppy, for a Kölsch"*?
  
<br>    
    
- Does the style Kölsch even describe a well-defined beer sub-group?
    - Would it be reliably distinguishable from non-Kölschs in a blind taste test?
    
    
How did this come about?
========================================================
`Beer   ==   water + malted barley + hops + yeast + `

`sometimes other stuff like fruit`

<br> 

- We categorize it into different styles based on 
  - Type and ratio of ingredients
  - How the beer is made (e.g., how long and at what temperature it's brewed)
  - Regional and historical differences 
  

How did this come about?
========================================================

BUT

- *How well do styles actually demarcate the beer landscape?*
  - Is there actually more inter-style variation than intra-style variation?
  - Is there a more empiricially clean way to categorize beers into super-groups?

In other words, we're asking: are beer styles just a social construct?


The Order of Things, theoretically
========================================================

<center>![order_of_things](./img/magnificent-chart-of-beer.jpg)<center>


Implications
========================================================


* If styles do demarcate the beer landscape well, we should expect to see distinct **clusters** dominated mostly by beers classified into a *single* style

* It should also be easy to <strong>predict</strong> style from the other variables

This all assumes the variables we have (more on those in a sec) can account for most of the variance between styles.


*The stakes could not be higher*.



Step 1: GET Beer
========================================================
### The age-old dilemma


From where?
[BreweryDB](http://www.brewerydb.com/developers/docs), an online database of beers with a public API.

![get_beers](./img/get_beers.jpg)

***

![get_beers](./img/example_beer.jpg)


Step 1: GET one Beer
========================================================

Once we've got a key, we can use a beer's unique BreweryDB ID and our key to get data on that beer.

<small>`http://api.brewerydb.com/v2/beer/<BEER_ID_HERE>/?key=/<YOUR_KEY_HERE>` </small>

In the browser, that looks like:

<center>![got_a_beer](./img/got_a_beer.jpg)</center>


Step 1: GET one Beer
========================================================
class: small-code

```{r eval=TRUE}
base_url <- "http://api.brewerydb.com/v2"
key_preface <- "/?key="

get_beer <- function(id) {
  fromJSON(paste0(base_url, "/beer/", id, "/", key_preface, key))
}
```


We can make a little function from this that'll take a single ID and use `fromJSON` to convert from, well, JSON into a nested list starting with our 200 success message.

```{r, eval=TRUE}
get_beer("GZQpRX")
```



Quick funciton factory
========================================================
class:small-code

Using `purrr::walk()` and `assign()` we can create functions to GET any beer, brewery, category, etc. if we know its ID.

```{r func_fac, eval = TRUE, echo=TRUE}
endpoints <- c("beer", "brewery", "category", "event", "feature", "glass", "guild", "hop", "ingredient", "location", "socialsite", "style", "menu")

# Base function
get_ <- function(id, ep) {
  jsonlite::fromJSON(paste0(base_url, "/", ep, "/", id, "/", key_preface, key))
}

# Create new get_<ep> functions
endpoints %>% walk(~ assign(x = paste0("get_", .x),
                             value = partial(get_, ep = .x),
                             envir = .GlobalEnv))
```

Now we have the functions `get_beer()`, `get_brewery()`, `get_category()`, etc. in our global environment.

Testing testing
========================================================
class:small-code


```{r, eval=TRUE, echo=TRUE}
get_hop("3")
```


Digging In
========================================================
class:very-small-code

What are the parts of the data that we want and where do they live? 

```{r, echo=TRUE, eval=TRUE}
get_beer("GZQpRX")
```

***

We can grab just the fourth element of the `data` part of the response, the beer's `description` in a couple ways:
```{r, echo=TRUE, eval=TRUE}
get_beer("GZQpRX")$data$description
```

Or in other words:
```{r, echo=TRUE, eval=TRUE}
get_beer("GZQpRX")[["data"]][4][[1]]
```


Digging In
========================================================
class:very-small-code

Other things are more deeply nested. 

```{r, echo=TRUE, eval=TRUE}
get_beer("GZQpRX")$data$style
```

***

In these cases, we really only care about the `name` portion.

```{r, echo=TRUE, eval=TRUE}
get_beer("GZQpRX")$data$style$name
```



Unnesting
========================================================
class:small-code

So, we'll unravel the `data` part of the response, grab whatever we want there, and glue it together into a dataframe. 

If the particular list item we're unnesting has a `name` portion (like `$style$name`), great, we'll grab that for the column. Otherwise, we'll take whatever's first. 

```{r, eval=TRUE, echo=TRUE}
unnest_it <- function(lst) {
  unnested <- lst
  for(col in seq_along(lst[["data"]])) {
    if(! is.null(ncol(lst[["data"]][[col]]))) {
      if(! is.null(lst[["data"]][[col]][["name"]])) {
        unnested[["data"]][[col]] <- lst[["data"]][[col]][["name"]]
      } else {
        unnested[["data"]][[col]] <- lst[["data"]][[col]][[1]]
      }
    }
  }
  return(unnested)
}
```

This approach is a bit slow because it uses a a `for` loop `r emo::ji("pensive")`. Optimizing it is on the docket.


Grabbing all Beers
========================================================
Instead of `/beer/<BEER_ID>` we're now asking for `/beers`

<center>![grab_all_beers](./img/grab_all_beers.jpg)</center>


Paginating the Request
========================================================
class: small-code

We find out how many pages there are total and then send requests and unnest each until we hit `number_of_pages`.

```{r get_beer, eval=FALSE}
paginated_request <- function(ep, addition, trace_progress = TRUE) {    
  full_request <- NULL
  first_page <- fromJSON(paste0(base_url, "/", ep, "/", key_preface, key
                                , "&p=1"))
  number_of_pages <- ifelse(!(is.null(first_page$numberOfPages)), 
                            first_page$numberOfPages, 1)      

    for (page in 1:number_of_pages) {                               
    this_request <- fromJSON(paste0(base_url, "/", ep, "/", key_preface, key
                                    , "&p=", page, addition),
                             flatten = TRUE) 
    this_req_unnested <- unnest_it(this_request)    #  <- request unnested here
    
    if(trace_progress == TRUE) {message(paste0("Page ", this_req_unnested$currentPage))} # if TRUE, print the page we're on
    
    full_request <- bind_rows(full_request, this_req_unnested[["data"]])
  }
  return(full_request)
} 
```


Quick note on Ingredients
========================================================
class:small-code
A few apporaches I used:

* Concatenated into a single string during the unnesting process
  * `hop_name` and `malt_name` using this function  `r emo::ji("point_right")`
* Split out into one hop per column and one malt per column
  * `hops_name_1`, `hops_name_2`, etc.
* Sparse dataframe with each type of hop (like Cascade, Citra, etc.) as its own column
  * Value is either 1 or 0

<small> (Another would have been a nested list-col) </small>

***

<br>

```{r, eval=FALSE, echo=TRUE}
unnest_ingredients <- function(df) {
  df$hops_name <- NA
  df$malt_name <- NA

  for (row in 1:nrow(df)) {
    if (!is.null(df[["ingredients.hops"]][[row]][["name"]]) |
        !is.null(df[["ingredients.malt"]][[row]][["name"]])) {

      df[["hops_name"]][[row]] <- paste(df[["ingredients.hops"]][[row]][["name"]], collapse = ", ")

      df[["malt_name"]][[row]] <- paste(df[["ingredients.malt"]][[row]][["name"]], collapse = ", ")
    }
  }
  return(df)
}
```



What have we got?
========================================================
class: small-code

```{r, echo=TRUE, eval=FALSE}
beer_necessities <- paginated_request(ep = "beers", addition = "&withIngredients=Y")
```


```{r, echo=FALSE, eval=TRUE, fig.align="center"}
kable(beer_necessities[115:120, ] %>% select(id, name, style, style_collapsed, glass, abv, ibu, srm, hops_name, malt_name))
```



What have we got?
========================================================

<div class="footer" style="font-size:80%; margin-bottom:0%">
What we have <em>not</em> got: flavor profiles (fruity, hoppy, piney) and ratings.</div>

<br> 
* `r format(nrow(beer_necessities), big.mark = ",")` distinct beers
* Info about the beer:
  * ABV: alcohol by volume
  * IBU: International Biterness Units (really)
  * SRM: [a measure of color](http://www.twobeerdudes.com/beer/srm)
  * Ingredients
      * Hops, malts
      
***

```{r, echo=FALSE, eval=TRUE}
ggplot(data = beer_necessities) +
  geom_line(aes(abv), alpha = 1, colour = "black", stat = "density") +
  geom_line(aes(ibu), alpha = 1, colour = "black", stat = "density", linetype = "dashed") +
  geom_line(aes(srm), alpha = 1, colour = "black", stat = "density", linetype = "dotted") +
  # geom_density(aes(abv), alpha = 0.5, fill = "green", alpha = 0.5) +
  # geom_density(aes(ibu), alpha = 0.5, fill = "blue", alpha = 0.5) +
  # geom_density(aes(srm), alpha = 0.5, fill = "brown", alpha = 0.5) +
  theme_minimal() +
  geom_text(aes(label = "ABV", x = 20, y = 0.25), size = 7, 
            colour = "black") +
  geom_text(aes(label = "IBU", x = 70, y = 0.03), size = 7,
            colour = "black") +
  geom_text(aes(label = "SRM", x = 21, y = 0.07), size = 7,
            colour = "black") +
  xlim(0, 125) +
  ggtitle("Distribution of ABV, IBU, SRM") +
  labs(x = "Measure", y = "Density")
  
```




Where to put it?
========================================================

<br>

![local_db](./img/local_db.jpg)

***

<br>

I threw it into MySQL

* This allows us to
   * Easily update the data if anything changes
   * Others easy access to the data if they want to build an app using it
   
<br>


Step 1 Complete   `r emo::ji("heavy_check_mark")`
   


A look at our outcome variable
========================================================
class:small-code

We have `r length(levels(beer_necessities$style))` styles of beer.

```{r, eval=TRUE}
levels(beer_necessities$style)
```

***

<br> 

What's the best way to condense these?

I want to e.g., lump American-Style India Pale Ale in with English-Style India Pale Ale.


   

Step 2: Breathe sigh of relief, Collapse
========================================================
class: small-code

```{r keywords, eval=TRUE}
keywords <- c("Pale Ale", "India Pale Ale", "Double India Pale Ale", "Lager", "India Pale Lager", "Hefeweizen", "Barrel-Aged","Wheat", "Pilsner", "Pilsener", "Amber", "Golden", "Blonde", "Brown", "Black", "Stout", "Imperial Stout", "Fruit", "Porter", "Red", "Sour", "Kölsch", "Tripel", "Bitter", "Saison", "Strong Ale", "Barley Wine", "Dubbel")
```


```{r collapse_styles}
collapse_styles <- function(df, trace_progress = TRUE) {
  
  df[["style_collapsed"]] <- vector(length = nrow(df))
  
  for (beer in 1:nrow(df)) {
    if (grepl(paste(keywords, collapse="|"), df$style[beer])) {    
      for (keyword in keywords) {         
        if(grepl(keyword, df$style[beer]) == TRUE) {
          df$style_collapsed[beer] <- keyword    
        }                         
      } 
    } else {
      df$style_collapsed[beer] <- as.character(df$style[beer])       
    }
    if(trace_progress == TRUE) {message(paste0("Collapsing this ", df$style[beer], " to: ", df$style_collapsed[beer]))}
  }
  return(df)
}
```

Collapsing in Action
========================================================

Setting `trace_progress = TRUE`:

![get_beers](./img/collapse_styles.jpg)

***
* `keywords` are ordered from most general to most specific
  * If a beer's name matches multiple keywords, its `style_collapsed` is the **last** of those that appear in `keywords`
    
    
`American-Style Pale Ale`  `r emo::ji("right_arrow")`  `Pale Ale`

`American-Style India Pale Ale`  `r emo::ji("right_arrow")`  `India Pale Ale`



Popular Styles
========================================================

Let's see where most of the data is concentrated. 

* Popular defined as
   * Styles with above the mean number of beers per style (z-score > 0)
       * <small> Of course, this isn't a measure of popular consumption; just a reflection of the number of different beers we get from BreweryDB that are classified into that style </small>
   
<br>

* And then get a sense of where those styles fall in relation to one another
    * Style "centers" = mean ABV, IBU, and SRM of each style

```{r popular_styles, echo=FALSE, eval=TRUE}
# Pare down to only cases where style is not NA
beer_dat_pared <- beer_necessities[complete.cases(beer_necessities$style), ]

# Arrange by style popularity
style_popularity <- beer_dat_pared %>% 
  group_by(style) %>% 
  count() %>% 
  arrange(desc(n))

# Add a column that z-scores popularity
style_popularity <- bind_cols(style_popularity, 
                               n_scaled = as.vector(scale(style_popularity$n)))

# Find styles that are above a z-score of 0 (the mean)
popular_styles <- style_popularity %>% 
  filter(n_scaled > 0)

# Pare dat down to only beers that fall into those styles, so styles that are above mean popularity
popular_beer_dat <- beer_dat_pared %>% 
  filter(
    style %in% popular_styles$style
  ) %>% 
  droplevels() %>% 
  as_tibble()
```


```{r style_centers, eval=TRUE, echo=FALSE}
style_centers <- popular_beer_dat %>% 
  group_by(style_collapsed) %>% 
  add_count() %>% 
  summarise(
    mean_abv = mean(abv, na.rm = TRUE) %>% round(., digits = 2),
    mean_ibu = mean(ibu, na.rm = TRUE) %>% round(., digits = 2), 
    mean_srm = mean(srm, na.rm = TRUE) %>% round(., digits = 2),
    n = median(n, na.rm = TRUE)          # Median here only for summarise. Should be just the same as n
  ) %>% 
  arrange(desc(n)) %>% 
  drop_na() %>% 
  droplevels()

# Give some nicer names
style_centers_rename <- style_centers %>% 
  rename(
    `Collapsed Style` = style_collapsed,
    `Mean ABV` = mean_abv,
    `Mean IBU` = mean_ibu,
    `Mean SRM` = mean_srm,
    `Numer of Beers` = n
  )
```


Popular Styles
========================================================

```{r, echo=FALSE, eval=TRUE}
kable(style_centers_rename)
```




Style Centers
========================================================

If beer styles are really self-contained, beer in each style should cluster tightly around these points.

```{r, echo=FALSE, eval=TRUE, fig.align="center", fig.width=12, fig.height=12}
ggplot(data = style_centers %>% filter(style_collapsed %in% keywords)) +
  geom_point(aes(mean_abv, mean_ibu, colour = style_collapsed, size = n)) +
  ggtitle("Style Centers and their Popularity") +
  labs(x = "Mean ABV", y = "Mean IBU", colour = "Collapsed Styles",
       size = "Number of Beers") +
  theme_minimal()
```


To the main question
========================================================

*Do styles truly define distinct pockets of beer?*

If they do, we could expect styles to align with **clusters** generated using an unsupervised learning algorithm. 

* k-means
    * Splits observations into `k` clusters (we choose `k`)
    * Try to minimize the sum of squares between each datapoint and its assigned cluster center

<small>Note that we'll have to throw away rows that contain `NA` values in any of the variables we're using.</small>

What variables should we include?



What's in a Predictor?
========================================================
incremental:false

*A heuristic I used*:

##### Outputs
* Only measured **after** a beer been brewed
    * ABV, IBU, SRM
    
##### Style-Defined
* Dependent entirely on style
  * Serving glass

##### Inputs
* Only directly controlled by a brewer **before** a beer is brewed
    * Hops, malts


***

<br> 
<br> 

`r emo::ji("+1")`  predictor  

<br> 
<br> 
<br> 

`r emo::ji("-1")`   predictor  

<br> 

`r emo::ji("woman_shrugging_medium_light_skin_tone")`  predictor because chicken and egg problem  
    <small> Do brewers assign style first and then choose which ingredients to add, or vice versa? `r emo::ji("hatching_chick")` </small>


Clustering: Let's have a function
========================================================
class: small-code

```{r, eval=TRUE, echo=FALSE}
set.seed(9)
```


```{r do_cluster_func, eval=FALSE}
do_cluster <- function (df, vars, to_cluster_on, n_centers = 5) {
  df_for_clustering <- df %>% select(!!vars) %>% na.omit()

  # Scale the ones to be scaled and append _scaled to their names
  df_vars_scale <- df_for_clustering %>% select(!!to_cluster_on) %>%
    scale() %>% as_tibble()
  names(df_vars_scale) <- names(df_vars_scale) %>% stringr::str_c("_scaled")

  # Do the clustering on the scaled data
  clusters_out <- kmeans(x = df_vars_scale, centers = n_centers, trace = FALSE)

  # Combine cluster assignment, scaled data, and unscaled rest of data
  clustered_df <- bind_cols(
    cluster_assignment = factor(clusters_out$cluster),   # Cluster assignment
    df_vars_scale,
    df_for_clustering
  )

  return(clustered_df)
}
```

<br>

<small> We don't need to specify an outcome variable because this is unsupervised. </small>


Clustering: Run It
========================================================
class: small-code

We'll cluster the beers on the scaled versions of ABV, IBU, and SRM 

```{r, eval=TRUE}
to_include <- c("id", "name", "style", "style_collapsed", "abv", "ibu", "srm")

to_cluster_on <- c("abv", "ibu", "srm")
```

<br>

and stitch together the cluster assignments, scaled columns, and the original data.

```{r run_do_cluster, eval=TRUE}
clustered_beer <- do_cluster(beer_dat, to_include, to_cluster_on)
```



Clustering: Output
========================================================

```{r clustered_beer, eval=TRUE, echo=FALSE, dependson = "source_in"}
clustered_beer_caps <- clustered_beer
names(clustered_beer_caps) <- names(clustered_beer) %>% map(dobtools::cap_a_word_partial, words_to_cap) %>% map(cap_it) %>% as_vector()
kable(clustered_beer_caps[1:30, ])
```


Clustering: Plot
========================================================
class:very-small-code

<small> Color vs. bitterness with style centers overlaid: </small>


```{r cluster_srm_ibu, echo=FALSE, eval=TRUE, fig.align="center", fig.width=9, fig.height=8}
clustered_beer_plot_srm_ibu <- ggplot() +
  geom_jitter(data = clustered_beer %>% select(abv, ibu, srm, cluster_assignment) %>% dobtools::trim_outliers(exclude = "cluster_assignment", cutoff = 2.5), 
             aes(x = srm, y = ibu, colour = cluster_assignment), alpha = 0.5) +
  geom_point(data = style_centers,
             aes(mean_srm, mean_ibu), colour = "black") +
  theme_minimal()  +
  geom_text_repel(data = style_centers, aes(mean_srm, mean_ibu, label = style_collapsed), 
                  box.padding = unit(0.45, "lines"),
                  family = "Calibri",
                  label.size = 0.3) +
  ggtitle("k-Means Clustering of Beer: SRM vs. IBU") +
  labs(x = "SRM", y = "IBU") +
  labs(colour = "Cluster Assignment") +
  theme(legend.position="none")
clustered_beer_plot_srm_ibu

```

***

<br>

<small>Here I've trimmed outliers using this function with a `cutoff = 2.5`.</small>

```{r trim_outliers, echo=TRUE, eval=FALSE}
trim_outliers <- function(df, cutoff = 1.96, exclude = NULL, keep_scaled = TRUE){

  to_scale <- names(df)[!names(df) %in% exclude]

  df_scaled <- df %>%
    select(!!to_scale) %>%
    transmute_if(
      is.numeric, scale
    )
  names(df_scaled) <- names(df_scaled) %>% stringr::str_c("_scaled")

  df_out <- bind_cols(df_scaled, df)

  df_out_trimmed <- df_out %>%
    filter_at(
      .vars = vars(contains("_scaled")),
      .vars_predicate = all_vars(. < abs(cutoff))
    )

  if(keep_scaled == FALSE) {
    df_out_trimmed <- df_out_trimmed %>% select(!!names(df))
  }

  return(df_out_trimmed)
}
```

<small> (You can grab it from my [`dobtools`](https://github.com/aedobbyn/dobtools) package on GitHub if you like.) </small>



Narrowing In
========================================================
incremental:false

```{r style_centers_certain_styles, eval=TRUE, echo=FALSE}
styles_to_keep <- c("Blonde", "India Pale Ale", "Stout", "Tripel", "Wheat")
bd_certain_styles <- beer_dat %>%
  filter(
    style_collapsed %in% styles_to_keep
  ) %>% 
  droplevels()

include <- c("id", "name", "style", "style_collapsed", "abv", "ibu", "srm", "total_hops", "total_malt")
to_scale <- c("abv", "ibu", "srm", "total_hops", "total_malt")

certain_styles_clustered <- dobtools::do_cluster(bd_certain_styles, include, to_scale)

style_centers_certain_styles <- style_centers %>% 
  filter(style_collapsed %in% styles_to_keep)

```

<br>

<small> If we focus in on 5 distinct styles and cluster them into 5 clusters, will each style be siphoned off into its own cluster? </small>

```{r, eval=TRUE, echo=FALSE, fig.width=12, fig.height=12}
kable(table(style = certain_styles_clustered$style_collapsed, cluster = certain_styles_clustered$cluster_assignment))
```


    
***


```{r cluster_certain_styles, eval=TRUE, echo=FALSE, fig.width=9, fig.height=9, fig.align="center"}
by_style_plot <- ggplot() +   
  geom_point(data = certain_styles_clustered %>% select(abv, ibu, srm, cluster_assignment, style_collapsed) %>% 
               dobtools::trim_outliers(exclude = c("cluster_assignment", "style_collapsed"), cutoff=3), 
             aes(x = abv, y = ibu,
                 colour = cluster_assignment), alpha = 0.5) +
  facet_grid(. ~ style_collapsed) +
  geom_point(data = style_centers_certain_styles,
           aes(mean_abv, mean_ibu), shape = 1, colour = "black", fill="black", size = 4) +
  ggtitle("Selected Styles Cluster Assignment") +
  labs(x = "ABV", y = "IBU") +
  labs(colour = "Cluster") +
  theme_bw()
by_style_plot
```

<!-- Not bad; without some taste data or other ingredients, it would be difficult to distinguish wheat beers and blonde ales. -->



Clusterfun with Shiny: UI
========================================================
class: small-code 

Snapshot of what we're including on the frontend:

```{r shiny_ui, eval=FALSE}
sidebarLayout(
    sidebarPanel(
      h4("Control Panel"),

      checkboxInput("show_all", "Show all styles", TRUE),      
      checkboxInput("show_centers", "Show style centers", FALSE),
      numericInput("num_clusters", "Number of Clusters:", starting_n_clusters),
      
      checkboxGroupInput("cluster_on", "Choose variables to cluster on: ",
                         c("ABV (alcohol)" = "abv", 
                           "IBU (bitterness)" = "ibu", 
                           "SRM (color)" ="srm", 
                           "Total number of hops" = "total_hops", 
                           "Total number of malts" = "total_malt"),
                         selected = c("abv", "ibu", "srm")),
      
      checkboxGroupInput("response_vars", "Choose response variable(s): ",
                         c("Collapsed style" = "style_collapsed",
                           "Specific style" = "style"
                         ),
                         selected = c("style_collapsed")),
      
      conditionalPanel(
        condition = "input.show_all == false",
        selectInput("style_collapsed", "Collapsed Style:",
                    style_names)
        )
    ),
```



Clusterfun with Shiny: Server
========================================================
class: small-code 

And how the backend is serving up that data, conditional on what the user asks it to display.

```{r shiny_server, eval=FALSE}
  output$cluster_plot <- renderPlot({
  
    # If our checkbox is checked saying we do want style centers, show them. Else, don't.
    if (input$show_all == FALSE & input$show_centers == TRUE) {
      
      this_style_center <- reactive({style_centers %>% filter(style_collapsed == input$style_collapsed)})
      
      ggplot() +
        geom_point(data = this_style_data(),
                   aes(x = abv, y = ibu, colour = cluster_assignment), alpha = 0.5) +
        geom_point(data = this_style_center(),
                   aes(mean_abv, mean_ibu), colour = "black") +
        geom_text_repel(data = this_style_center(),
                        aes(mean_abv, mean_ibu, label = input$style_collapsed),
                        box.padding = unit(0.45, "lines"),
                        family = "Calibri") +
        ggtitle("k-Means Clustered Beer") +
        labs(x = "ABV", y = "IBU") +
        labs(colour = "Cluster Assignment") +
        theme_minimal() +
        theme(legend.position="none")
    } else if  # ....... etc., etc.
```



Clusterfun with Shiny
========================================================

<small><https://amandadobbyn.shinyapps.io/clusterfun/></small></center>

<center>![clusterfun](./img/clusterfun.jpg)




And now for something completely different
========================================================
<div class="midcenter" style="width:90%; height:90%; margin-right:30%"> <img src="./img/now_for_something_completely_different.gif"></img></div>

...a quick dive into hops


Hops
========================================================
incremental:true


<div class="midcenter" style="margin-left:-300px; margin-top:-300px;">
<img src="./img/mad_hops.jpg"></img>
</div>



Hops
========================================================
incremental:true

No, not those hops!

![fresh_hops](./img/fresh_hops.jpg)

These hops `r emo::ji("point_up")`

*** 

Hops `\häps\`, *n*: 1. It's what makes beer bitter and flavorful.

<br>

One question: do more *kinds* of hops generally make a beer more bitter?

<small>(This is different than the total *quantity* of hops used during brewing.)</small>


Hops Munge
========================================================
class: small-code

Let's munge a bit. We'll need to split out ingredients from one column into many.


```{r, eval=TRUE, echo=TRUE}
split_ingredients <- function(df, ingredients_to_split) {
  ncol_df <- ncol(df)
  
  for (ingredient in ingredients_to_split) {
    ingredient_split <- str_split(df[[ingredient]], ", ")    
    num_new_cols <- max(lengths(ingredient_split))    
    
    for (num in 1:num_new_cols) {
      this_col <- ncol_df + 1         
      df[, this_col] <- NA
      names(df)[this_col] <- paste0(ingredient, "_", num)
      ncol_df <- ncol(df)             
      
      for (row in seq_along(ingredient_split)) {          
        if (!is.null(ingredient_split[[row]][num])) {        
          df[row, this_col] <- ingredient_split[[row]][num]
        }
      }
      df[[names(df)[this_col]]] <- factor(df[[names(df)[this_col]]])
    }
    ncol_df <- ncol(df)
  }
  return(df)
}
```

```{r make_beer_dat, eval=FALSE, echo=TRUE}
beer_necessities <- split_ingredients(beer_necessities, 
                              ingredients_to_split = c("hops", "malt"))
```


Hops Munge
========================================================
class: small-code

```{r get_pop_hops_2, echo=TRUE, eval=TRUE}
# Gather up all the hops columns into one called `hop_name`
beer_necessities_hops_gathered <- beer_necessities %>%
  gather(
    hop_key, hop_name, hops_name_1:hops_name_13
  ) %>% as_tibble()

# Filter to just those beers that have at least one hop
beer_necessities_w_hops <- beer_necessities_hops_gathered %>% 
  filter(!is.na(hop_name)) %>% 
  filter(!hop_name == "")

beer_necessities_w_hops$hop_name <- factor(beer_necessities_w_hops$hop_name)

# For all hops, find the number of beers they're in as well as those beers' mean IBU and ABV
hops_beer_stats <- beer_necessities_w_hops %>% 
  ungroup() %>% 
  group_by(hop_name) %>% 
  summarise(
    mean_ibu = mean(ibu, na.rm = TRUE) %>% round(digits=2), 
    mean_abv = mean(abv, na.rm = TRUE) %>% round(digits=2),
    n = n()
  ) %>% 
  arrange(desc(n))

# Pare to hops that are used in at least 50 beers
pop_hops_beer_stats <- hops_beer_stats[hops_beer_stats$n > 50, ] 

pop_hops_display <- pop_hops_beer_stats %>% 
    rename(
    `Hop` = hop_name,
    `Mean IBU` = mean_ibu,
    `Mean ABV` = mean_abv,
    `N Beers` = n
  )
```


What's the hop landscape look like?
========================================================

Hops contained in >50 beers:

```{r, echo=FALSE, eval=TRUE, dependson="get_pop_hops_2"}
kable(pop_hops_display[1:11,])
```

***

<br>

```{r eval=TRUE, echo=FALSE, dependson="get_pop_hops_2"}
kable(pop_hops_display[12:20,])
```



Hop Landscape
========================================================
incremental: false
class: small-code

<br>

Per hop, number beers containing that hop and their average ABV and IBU.

<br>

Note that there is actually, irl, a strain of hops called Fuggles.

<br>

Q: Do more *kinds* of hops generally make a beer more bitter?

***

<br>

```{r, eval=TRUE, echo=FALSE, fig.align="center", fig.width=9, fig.height=8}
ggplot(data = pop_hops_beer_stats) + 
  geom_point(aes(mean_abv, mean_ibu, colour = hop_name, size = n)) +
  ggtitle("Most Popular Hops' Effect on Alcohol and Bitterness") +
  labs(x = "Mean ABV per Hop Type", y = "Mean IBU per Hop Type", colour = "Hop Name", 
       size = "N Beers") +
  theme_minimal()
```




How do hops affect bitterness?
========================================================
class:small-code
incremental:true

```{r, eval=TRUE, echo=FALSE}
ggplot(data = beer_dat %>% filter(style_collapsed %in% keywords) %>% filter(total_hops > 0), aes(total_hops, ibu)) +
  geom_jitter(aes(total_hops, ibu, colour = style_collapsed), width = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess", se = FALSE, colour = "black") + 
  ggtitle("Hops Per Beer vs. Bitterness") +
  labs(x = "Number of Hops", y = "IBU", colour = "Style Collapsed") +
  theme_minimal()
```

Is the relationship significant?

***

```{r hops_ibu_lm, echo=TRUE, eval=TRUE}
hops_ibu_lm <- lm(ibu ~ total_hops, 
  data = beer_dat %>% filter(total_hops > 0)) %>% 
  broom::tidy() %>% dobtools::style_lm() 
```

```{r, echo=FALSE, eval=TRUE, fig.align="center"}
hops_ibu_lm %>% as.data.frame()
```

<small>We can expect an increase in around `r round(hops_ibu_lm$Estimate, digits = 0)` IBU for every 1 extra hop.</small>

Okay back on track!

![onward](./img/onward.gif)




Prediction
========================================================
* The other side of the coin: supervised learning classification problem
    * Random forest
    * Neural network
    
We'll go through the neural net.

<br> 

A <em>low prediction error rate</em> should indicate that styles are well-defined, at least by the variables that we have. 


Prediction: Neural Net
========================================================

* Package: `nnet`
* Outcome variable: `style` or `style_collapsed`

**What we'll do**
* Feed it a dataframe, an outcome variable, and a set of predictor variables
* It will train it 80%, test on 20%
    * From this, we can get a measure of accuracy
    
    
Neural Net: the Function
========================================================
class: small-code

```{r nn_func, warning=FALSE, echo=TRUE, eval=FALSE}
run_neural_net <- function(df, multinom = TRUE, outcome, predictor_vars,
                           maxit = 500, size = 5, trace = FALSE, seed = NULL) {
  out <- list(outcome = outcome)
  
  # Create a new column outcome; it's style_collapsed if you set outcome to style_collapsed, and style otherwise
  if (outcome == "style_collapsed") {
    df[["outcome"]] <- df[["style_collapsed"]]
  } else {
    df[["outcome"]] <- df[["style"]]
  }
    
  cols_to_keep <- c("outcome", predictor_vars)
  
  df <- df %>%
    select_(.dots = cols_to_keep) %>%
    mutate(row = 1:nrow(df)) %>% 
    droplevels()
  
  # Select 80% of the data for training
  df_train <- sample_n(df, nrow(df)*(0.8)) %>% droplevels()
  
  # The rest is for testing
  df_test <- df %>%
    filter(! (row %in% df_train$row)) %>%
    select(-row)
  
  df_train <- df_train %>%
    select(-row)
```

***

```{r, echo=TRUE, eval=FALSE}

  if(multinom==TRUE) {
    nn <- multinom(outcome ~ .,
                   data = df_train, maxit=maxit, trace=trace)
    
    # Which variables are the most important in the neural net?
    most_important_vars <- varImp(nn)
    
  } else if (multinom==FALSE) {
    nn <- nnet(outcome ~ ., size = size,
                   data = df_train, maxit=maxit, trace=trace)
    most_important_vars <- NULL

  }
  
  # How accurate is the model? Compare predictions to outcomes from test data
  nn_preds <- predict(nn, type="class", newdata = df_test) %>% factor()
  nn_accuracy <- postResample(df_test$outcome, nn_preds)
  
  out <- list(out, nn = nn, 
              most_important_vars = most_important_vars,
              df_test = df_test,
              nn_preds = nn_preds,
              nn_accuracy = nn_accuracy)
  
  return(out)
}
```


Neural Net: Run It
========================================================
class: small-code

Our predictors will include the total number of hops and malts in the beer, plus our usual ABV, IBU, SRM.

```{r eval=TRUE}
p_vars <- c("total_hops", "total_malt", "abv", "ibu", "srm")
```

We'll use data filtered to just the most popular styles and run it. 

```{r nn_run, eval=TRUE, echo=TRUE, dependson="source_run_nn"}
nn_collapsed_out <- run_neural_net(df = beer_dat %>% drop_na(!!p_vars), outcome = "style_collapsed", predictor_vars = p_vars, size = 10, trace = TRUE, multinom = FALSE, seed = 9)
```


Neural Net: Visual
========================================================
class: small-code

We can check out the structure of the neural net using the `NeuralNetTools` package.

We can see we've got one hidden layer and two bias nodes.

```{r, echo=TRUE, eval=TRUE, dependson="nn_run", fig.align="center", fig.width=12}
par(mar=c(4.1, 0.1, 4.1, 7.1))
NeuralNetTools::plotnet(nn_collapsed_out$nn, line_stag = 0.01, max_sp = TRUE)
```



```{r, echo=FALSE, eval=FALSE, dependson="nn_run"}
nnet_plot <- NeuralNetTools::plotnet(nn_collapsed_out$nn) %>% recordPlot()
wts <- NeuralNetTools::plotnet(nn_collapsed_out$nn, wts_only=TRUE)
```




Neural Net: Evaluate
========================================================
class: small-code

<br> 

How'd we do? 

```{r, eval=TRUE}
nn_collapsed_out$nn_accuracy[1]
```

<br> 

`r round((nn_collapsed_out$nn_accuracy[1] * 100), digits=1)`% isn't terrible given we've got `r length(levels(beer_dat$style_collapsed))` collapsed styles; chance would be `r round((100 / length(levels(beer_dat$style_collapsed))), digits = 1)`%.


***

<br> 

Which variables are most important?

<small> `caret::varImp` will give us an importance measure using combinations of the absolute values of the weights </small>

```{r, echo=FALSE, eval=FALSE}
get_nn_importance <- function(nn, keep_gini = FALSE) {

  importance_df <- nn %>% caret::varImp()
  names <- importance_df %>% row.names()

  importance_df <- importance_df %>%
    as_tibble() %>% select(Overall) %>%
    dplyr::arrange(desc(Overall)) %>%
    bind_cols(Variable = names) %>%
    rename(Importance = Overall) %>%
    mutate(
      `Importance Percent` = ((Importance/sum(.$Importance))) %>% round(digits=3) %>%
        scales::percent()
    )

  if(keep_gini == FALSE) {
    importance_df <- importance_df %>% select(-Importance)
  }

  return(importance_df)
}
```


```{r, eval=TRUE, echo=FALSE}
nn_collapsed_multinom <- run_neural_net(df = beer_dat %>% drop_na(!!p_vars), outcome = "style_collapsed", predictor_vars = p_vars, trace = FALSE, multinom = TRUE)

nn_collapsed_multinom$nn %>% get_nn_importance() %>% kable()
```


Neural Net: Glass
========================================================
class:small-code

What happens if we add in glass, a style-dependent attribute, as a predictor?

```{r p_vars_add_glass, eval=TRUE, echo=TRUE}
p_vars_add_glass <- c("total_hops", "total_malt", "abv", "ibu", "srm", "glass")
```

``` {r add_glass, eval=TRUE, echo=TRUE, message=FALSE, dependson="source_run_nn"}
nn_collapsed_out_add_glass <- run_neural_net(df = beer_dat %>% drop_na(!!p_vars_add_glass), outcome = "style_collapsed", predictor_vars = p_vars_add_glass, trace = FALSE, multinom = FALSE)
```

```{r add_glass_accuracy, eval=TRUE, echo=FALSE}
nn_collapsed_out_add_glass$nn_accuracy[1]
```

<br> 

That's `r round(((nn_collapsed_out_add_glass$nn_accuracy[1] - nn_collapsed_out$nn_accuracy[1]) * 100), digits=2)` percentage points more accurate than the model without glass included.


***

``` {r add_glass_multinom, eval=TRUE, echo=FALSE, message=FALSE, dependson="source_run_nn"}
nn_collapsed_out_add_glass_multinom <- run_neural_net(df = beer_dat %>% drop_na(!!p_vars_add_glass), outcome = "style_collapsed", predictor_vars = p_vars_add_glass, trace = FALSE, multinom = TRUE)  
```


```{r make_nn_glass_imp_all, eval=TRUE, echo=FALSE, dependson="add_glass_multinom"}
# Sum up glass contributions
nn_glass_imp <- nn_collapsed_out_add_glass_multinom$nn %>% get_nn_importance(keep_gini = TRUE)
glass_cols <- nn_glass_imp$Variable[grepl("glass", nn_glass_imp$Variable)]

glass_sums <- nn_glass_imp %>%  
  filter(Variable %in% !!glass_cols) %>% 
  summarise(
    Importance = sum(Importance),
    `Importance Percent` = (sum(as.numeric(sub("%", "", `Importance Percent`)))/100) %>% round(digits = 5) %>% scales::percent()
  ) %>% mutate(
    Variable = "glass"
  )

nn_glass_imp_all <- nn_glass_imp %>% 
  filter(!Variable %in% !!glass_cols) %>% 
  bind_rows(
   glass_sums
  ) %>% arrange(desc(Importance)) %>% 
  select(
    -Importance
  )
```

Here summing up the contributions from all glasses.


```{r display_nn_glass_imp_all, eval=TRUE, echo=FALSE, dependson="make_nn_glass_imp_all"}
kable(nn_glass_imp_all)
```



So what's the answer?
========================================================
*Are beer styles a useful construct to use as a proxy for natural clusters in beer?*

I'd give it a fuzzy yes.

Fuzzy because:
* We couldn't do better than ~`r round((nn_collapsed_out$nn_accuracy[1] * 100), digits = -1)`% accuracy
* We had a lot of rows with missing predictors

Unknowns:
* Was our style collapsing scheme successful in putting beers in the "right" buckets?
* Would taste-related information have accounted for much of the remaining variance we couldn't explain?


So what's the answer?
========================================================

<br>

```{r, echo=FALSE, eval=TRUE, fig.width=9, fig.height=8, fig.align="center"}
ggplot() +   
  geom_density2d(data = beer_necessities %>% filter(style_collapsed %in% keywords) %>% 
               filter(abv < 20 & abv > 3 & ibu < 200), 
             aes(x = abv, y = ibu, colour = style_collapsed), alpha = 0.5) +
  ggtitle("Beer Styles, ABV vs. IBU") +
  labs(x = "ABV", y = "IBU") +
  labs(colour = "Collapsed Style") +
  theme_minimal()
```

***

<br>

Plotting the landscape directly on our two main dimensions,

* Syles are very overlapping, especially among lower-alcohol and -bitterness styles
* But, no clear super-groups that are independent of style




Future Directions
========================================================
In no particular order, some thoughts I've had plus suggestions from others:

* More Shiny app features
    * Beer searchability, tooltips over each point on hover
* Join on other data
  * e.g., [Untappd](!https://untappd.com/) or something scraped from the interwebs
* Beer consumption: how is this trending over time, for each style?
    * What drives the trend? Supply or demand?
        * <small> Do brewers brew more sours causing people buy more of them or do people start liking sours and cause brewers to brew more? </small>
* Hierarchical clustering to make a more scientific beer family tree
* Some funky algorithm to generate new beer names


Cheers, all!
========================================================
class: cheers

```{r, eval=TRUE, echo=FALSE}
sessionInfo()
```






